---
title: 从零开始的机器学习生活——朴素贝叶斯分类器（I）
categories: Techno
tags:
  - Machine Learning
---

最近，人工智能（AI）这一概念进入了越来越多的大众的视野之中。人们似乎突然之间发现AI技术已经可以解决过去被认为是无法解决的事情。例如，围棋曾被认为是机器无法胜过人类的一种游戏。但是AlphaGo的横空出世标志了计算机在围棋领域领先了人类。AI技术提升如此之快离不开机器学习（ML）在最近十年的快速进步。本篇文章将介绍机器学习中一种简单的分类方法——朴素贝叶斯分类器（Naive Bayesian Classifier, NBC）。

## 一个简单的问题——人是如何学习的
机器学习本质上是通过喂给机器数据，让机器从数据中学习到规律。然后让机器利用学习到的规律对未知的数据进行推断。说到学习，人之所以能够在自然界中成为强大的物种，倚赖的就是人千万年来积累的知识。这些知识是祖祖辈辈的人们从生活中总结出来的。所以，这里首先让我们回顾一下人类选手是如何学习知识的。试想小时候，父母在带我们出门的时候，常常会指着路边商店的一个牌子，问其中某个字怎么念。如果念对了，父母会很高兴地说：“我崽真聪明！”，晚上搞不好还有加餐。念错了，父母就会纠正：“XX应该念XX啊。”这是一个人类学习的一个典型事例，人类可以从例子中去学习，通过得到的正反馈或者负反馈去修正脑内尚未成型概念，经过多次的反复，就学到了一个概念。那么很自然的就有这样一个问题——机器也可以这样学习吗？呃，答案是可以的。但是肯定不能够照搬上面的过程。毕竟，机器的世界中只有数字，我们需要一种方法把这一过程“翻译”给机器。在ML界，有可以说是玄学的方法，也有思路比较清晰的方法。这里，我们先介绍一种基于统计学的方法——朴素贝叶斯。

## 从贝叶斯定理说起
在学概率论的时候，大家一定会学到一个关于条件概率的一个公式：
$$
p(A|B) = \frac{p(B|A)p(A)}{p(B)}
$$
这就是著名的贝叶斯定理。从数学上来说，从条件概率的定义一步就可以推导出这一公式。但是，其背后却隐藏着一个下判断的深刻道理。这里先讲一个经典的例子[1]。

> 40岁左右的妇女可以通过一种叫做乳房摄影术的检查来检测是否患有早期乳癌。假设这种检查的*敏感度*（即如果患有癌症，检查呈现阳性的概率）是80%。如果一个妇女被检查出阳性，那么她患有乳癌的概率是多少？

如果是一个人被检查出阳性，想必已经是相当慌张了。然而，贝叶斯定理告诉我们，即使被检测出阳性，也不必要如此慌张。因为，被检测出阳性的情况下患上乳癌的概率仅为3%。为什么结果会与人类的直觉出现那么大的偏差？这里，我们使用数学语言去描述这样一个问题。

> 假设随机变量$X$指示检查的结果，$x=1$表示检查结果是阳性。随机变量$Y$指示受检者是否患有乳癌，$y=1$表示患有。我们现在知道的概率是$p(x=1|y=1)=0.8$。这个概率与我们关心的概率看起来很像，其实却有着很大的不同。
> 我们关心p(y=1|x=1)，即当检查结果是阳性时，患有受检者患有乳癌的条件概率。利用贝叶斯定理展开
> $$
> p(y=1|x=1) = \frac{p(x=1|y=1)p(y=1)}{p(x=1)}
> $$
> 我们提供以下的信息：
> 1. 在人群中，乳癌的发病率是0.4%。即$p(y=1) = 0.004$。
> 2. 受检者在并没有乳癌的情况下，被检测出阳性（假阳性）的概率是10%。即$p(x=1|y=0)=0.1$。
> 将以上数据代入上式有：
> $$
> \begin{eqnarray*}
> p(y=1|x=1) &=& \frac{p(x=1|y=1)p(y=1)}{p(x=1)} \\
>            &=& \frac{p(x=1|y=1)p(y=1)}{p(x=1|y=0)p(y=0)+p(x=1|y=1)p(y=1)} \\
>            &=& \frac{0.8 \times 0.004}{0.1 \times 0.996 + 0.8 \times 0.004} \\
>            &\approx& 0.003
> \end{eqnarray*}
> $$

出现这个结果的原因是这种检查在未患病人群中有相当高的误报率（FAR）——10%。这使得被检查出阳性的有极大概率是误报。当然，这件事情也告诉我们市场上有很多奸商会夸大利于它自己的信息。有的时候需要特别的小心。

## 利用概率进行决策
假如，我们知道一件事物$x$属于各个类别$c$的概率。即，我们可以精确地知道$p(y=c|x)$。当然，我们本能地就会认为概率最高那个类$\max\arg\_c p(y=c|x)$就是这个事物的类别。

## 参考文献
\[1\] Machine learning a probabilistic perspective
